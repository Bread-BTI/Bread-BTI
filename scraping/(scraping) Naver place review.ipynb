{"cells":[{"cell_type":"markdown","id":"63645ea0","metadata":{"id":"63645ea0"},"source":["모듈 임포트"]},{"cell_type":"code","execution_count":null,"id":"313babc1","metadata":{"id":"313babc1"},"outputs":[],"source":["from bs4 import BeautifulSoup \n","\n","import pandas as pd\n","\n","import selenium\n","from selenium import webdriver\n","from selenium.webdriver.common.keys import Keys \n","from selenium.webdriver.common.by import By\n","from selenium.webdriver.chrome.service import Service\n","from webdriver_manager.chrome import ChromeDriverManager\n","\n","import time\n","import re\n","from tqdm import tqdm\n","from lxml import etree"]},{"cell_type":"markdown","id":"85013f24","metadata":{"id":"85013f24"},"source":["크롬 드라이버 설치"]},{"cell_type":"code","execution_count":null,"id":"8d7b7d95","metadata":{"id":"8d7b7d95"},"outputs":[],"source":["chrome_options = webdriver.ChromeOptions()\n","driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)"]},{"cell_type":"markdown","id":"09735b24","metadata":{"id":"09735b24"},"source":["`빵집 이름`이 담긴 파일 가져오기\n","- `LISTLY` 사용하여 만든 엑셀 파일에서 이름만 따로 가져온다.\n","- 참고로 크롤링시 클릭이 먹히지 않기 때문에 해당 상호명을 검색했을 때, 원하는 지점 하나만 뜨도록 `빵집 이름`을 더 구체적으로 수정해준다. ex. 비파티세리->비파티세리 압구정\n","- 후에 만들어질 url 담을 컬럼도 만들어준다."]},{"cell_type":"code","execution_count":null,"id":"6868f98c","metadata":{"id":"6868f98c","outputId":"1813411c-d900-4592-ee05-c0f1d739d86d"},"outputs":[],"source":["df = pd.read_excel('서울시 마들렌 맛집] 리스트 (1018).xlsx') \n","df['naver_map_url'] = ''\n","df = df.drop(columns=['Unnamed: 0'])\n","df"]},{"cell_type":"markdown","id":"20c8e959","metadata":{"id":"20c8e959"},"source":["`빵집 이름` 이 담긴 컬럼의 이름을 \"검색어\"로 수정함.(엑셀)\n","1. 검색 url을 만들어 검색하고,\n","2. 검색된 플레이스의 페이지 url을 다시 가져온다.(검색 url의 가게코드 이용하는 원리로 추측됨.)\n","- 변수이름은 final_url. \n","- 없는 경우 공백 "]},{"cell_type":"code","execution_count":null,"id":"3a23850d","metadata":{"id":"3a23850d","scrolled":true},"outputs":[],"source":["for i, keyword in enumerate(df['검색어'].tolist()): \n","    \n","    print(\"이번에 찾을 키워드 :\", i, f\"/ {df.shape[0]} 행\", keyword) \n","    \n","    try: \n","        naver_map_search_url = f'https://map.naver.com/v5/search/{keyword}/place' # 검색 url 만들기 \n","        driver.get(naver_map_search_url)\n","        time.sleep(5)\n","\n","        cu = driver.current_url\n","        res_code = re.findall(r\"place/(\\d+)\", cu)\n","        final_url = 'https://pcmap.place.naver.com/restaurant/'+res_code[0]+'/review/visitor#' \n","        \n","        print(final_url)\n","        df['naver_map_url'][i]=final_url \n","        \n","    except IndexError: \n","        df['naver_map_url'][i]= ''\n","        print('none')"]},{"cell_type":"markdown","id":"cf240695","metadata":{"id":"cf240695"},"source":["### 각 매장별 리뷰 데이터프레임 만들기\n","리뷰 리스트 만들어서 데이터프레임으로 변환 후,\n","상호명 리스트(name_list)를 컬럼으로 지정함.\n","- 방법은 https://jenn1won.tistory.com/15 와 비슷하나,\n","- 필요하지 않은 데이터(작성자, 사진 등)은 코드에서 제거함.\n","- By , lxml 모듈에서 오류가 나서 따로 설치를 진행함.\n","- 셀렉터 값도 내 컴퓨터와 달라 수정해줌.  \n","- 더보기 버튼을 20번만 눌러서 약 200개 리뷰 수집\n","- 리뷰수가 다르면 데이터프레임 생성하는 데 오류 생겨서 리뷰수 200개로 잘라서 넣음."]},{"cell_type":"code","execution_count":null,"id":"99eff525","metadata":{"id":"99eff525","scrolled":false},"outputs":[],"source":["df_result=pd.DataFrame()\n","\n","for i in range(len(df)): \n","    review_list= []\n","    \n","    print('======================================================')\n","    \n","    # url 접속\n","    driver.get(df['naver_map_url'][i]) \n","    thisurl = df['naver_map_url'][i]\n","    time.sleep(2) \n","    \n","    # 더보기버튼 25번 클릭(한 번당 약 10개 뽑힌다. 넉넉히 25)\n","    num = 0\n","    while num < 25:\n","        try: \n","            time.sleep(1) \n","            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n","            time.sleep(3) \n","            \n","            driver.find_element(By.CSS_SELECTOR, '#app-root > div > div > div > div:nth-child(7) > div:nth-child(2) > div.place_section.lcndr > div.lfH3O > a').send_keys(Keys.ENTER) \n","            time.sleep(3) \n","            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END) \n","            time.sleep(1) \n","            num += 1\n","        except : 'none'\n","\n","    # 파싱\n","    html = driver.page_source \n","    soup = BeautifulSoup(html, 'lxml') \n","    time.sleep(1) \n","    \n","    # 식당 이름, 구분, 총 개수 출력\n","    restaurant_name = df['검색어'][i]\n","    print('식당 이름 : '+restaurant_name)\n","\n","    \n","    try: \n","        restaurant_classificaton = soup.find_all('span',attrs = {'class':'DJJvD'})[0].text \n","    \n","    except: \n","        restaurant_classificaton = 'none'\n","    \n","    print('식당 구분 : '+restaurant_classificaton)\n","    print('----------------------------------------------')\n","    \n","    try: \n","        one_review = soup.find_all('div', attrs = {'class':'ZZ4OK IwhtZ'})\n","        review_num = len(one_review) # 특정 식당의 리뷰 총 개수 \n","        print('리뷰 총 개수 : '+str(review_num)) \n","        \n","        # 목표치인 리뷰 200개씩만 모으기\n","        for i in range(200):\n","            \n","            try: \n","                review_content = one_review[i].find('span', attrs = {'class':'zPfVt'}).text\n","                review_list.append(review_content)\n","            except:\n","                review_content = \"\" \n","            print('리뷰 내용 : '+review_content) \n","            \n","      \n","    except NoSuchElementException: \n","        none_review = \"네이버 리뷰 없음\" \n","        print(none_review)\n","        review_num = 0 \n","        \n","    # 데이터 프레임 만들기\n","    df_result[f\"{restaurant_name}\"] = review_list.copy()"]},{"cell_type":"markdown","id":"Xjh3yebM-rp3","metadata":{"id":"Xjh3yebM-rp3"},"source":["**결과 출력**"]},{"cell_type":"code","execution_count":null,"id":"313a83b1","metadata":{"id":"313a83b1"},"outputs":[],"source":["df_result.to_excel('리뷰모음.xlsx')"]},{"cell_type":"code","execution_count":null,"id":"085e47f3","metadata":{"id":"085e47f3"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}
